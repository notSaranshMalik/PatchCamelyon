{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0054046",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccea3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomVerticalFlip, Grayscale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd753fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dbfea4c",
   "metadata": {},
   "source": [
    "### Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17845fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, train=0, gray=True):\n",
    "        \n",
    "        # Load data\n",
    "        self.train = (train == 0)\n",
    "        if train == 0:\n",
    "            self.x = self.load_h5_as_numpy('camelyonpatch_level_2_split_train_x.h5', 'x')\n",
    "            self.y = self.load_h5_as_numpy('camelyonpatch_level_2_split_train_y.h5', 'y')[:, 0, 0, 0]\n",
    "        elif train == 1:\n",
    "            self.x = self.load_h5_as_numpy('camelyonpatch_level_2_split_test_x.h5', 'x')\n",
    "            self.y = self.load_h5_as_numpy('camelyonpatch_level_2_split_test_y.h5', 'y')[:, 0, 0, 0]\n",
    "        elif train == 2:\n",
    "            self.x = self.load_h5_as_numpy('camelyonpatch_level_2_split_valid_x.h5', 'x')\n",
    "            self.y = self.load_h5_as_numpy('camelyonpatch_level_2_split_valid_y.h5', 'y')[:, 0, 0, 0]\n",
    "        self.gray = gray\n",
    "            \n",
    "        # Prepare transforms\n",
    "        self.t1 = RandomHorizontalFlip(p=0.5)\n",
    "        self.t2 = RandomVerticalFlip(p=0.5)\n",
    "        self.g = Grayscale()\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get images\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if type(idx) is list:\n",
    "            img = torch.from_numpy(self.x[idx].astype(np.float32)).permute(0, 3, 1, 2)/128 - 1\n",
    "            cls = torch.from_numpy(self.y[idx])\n",
    "        else:\n",
    "            img = torch.from_numpy(self.x[idx].astype(np.float32)).permute(2, 0, 1)/128 - 1\n",
    "            cls = self.y[idx]\n",
    "            \n",
    "        # Transforms\n",
    "        if self.train:\n",
    "            img = self.t1(self.t2(img))\n",
    "        if self.gray:\n",
    "            img = self.g(img)\n",
    "        \n",
    "        # Return\n",
    "        return (img, cls)\n",
    "    \n",
    "    def load_h5_as_numpy(self, file_name, key):\n",
    "        with h5py.File(file_name, 'r') as h5_file:\n",
    "            data = h5_file[key][:]\n",
    "        return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "691e509c",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b365dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout_rate=0.2, gray=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        first_deg = 1 if gray else 3\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(first_deg, 16, 3, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    \n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lin1 = nn.Sequential(\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lin2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lin3 = nn.Linear(128, 2)\n",
    "        \n",
    "        self.train_model = nn.Sequential(\n",
    "            self.conv,\n",
    "            self.drop,\n",
    "            self.lin1,\n",
    "            self.drop,\n",
    "            self.lin2,\n",
    "            self.drop,\n",
    "            self.lin3\n",
    "        )\n",
    "        \n",
    "        self.test_model = nn.Sequential(\n",
    "            self.conv,\n",
    "            self.lin1,\n",
    "            self.lin2,\n",
    "            self.lin3\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return self.train_model(x)\n",
    "        else:\n",
    "            return self.test_model(x)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be5981d8",
   "metadata": {},
   "source": [
    "### Training / Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b043d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.log_text = \"\"\n",
    "\n",
    "    def log(self, text):\n",
    "        self.log_text += (text + \"\\n\")\n",
    "        print(text)\n",
    "\n",
    "    def get_log(self):\n",
    "        return self.log_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c36a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, loss_fn, optimiser, epoch, train_name, save=False, patience=1, factor=0.4):\n",
    "    \n",
    "    # Setup\n",
    "    logger = Log()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, mode=\"max\", patience=patience, factor=factor, verbose=True)\n",
    "    train_loss = np.zeros(epoch)\n",
    "    valid_loss = np.zeros(epoch)\n",
    "    \n",
    "    # Main epoch loop\n",
    "    for i in range(epoch):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for inputs, labels in tqdm(train_dataloader, mininterval=1):\n",
    "            y_pred = model(inputs.to(dev))\n",
    "            loss = loss_fn(y_pred, labels.to(dev))\n",
    "            train_loss[i] += loss.item()\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        # Validating\n",
    "        model.eval()\n",
    "        acc = 0\n",
    "        loss = 0\n",
    "        for inputs, labels in tqdm(val_dataloader, mininterval=1):\n",
    "            y_pred = model(inputs.to(dev))\n",
    "            acc += (torch.argmax(y_pred, 1) == labels.to(dev)).float().sum()\n",
    "            valid_loss[i] += loss_fn(y_pred, labels.to(dev)).item()\n",
    "        acc = 100 * float(acc) / len(val_dataloader.dataset)\n",
    "        logger.log(f\"Epoch {i+1}: validation accuracy {round(acc, 2)}\")\n",
    "        scheduler.step(acc)\n",
    "        \n",
    "    # Normalise loss data\n",
    "    train_loss = 100 * train_loss / len(train_dataloader)\n",
    "    valid_loss = 100 * valid_loss / len(val_dataloader)\n",
    "        \n",
    "    # Create the loss plot\n",
    "    epochs = np.arange(1, epoch+1)\n",
    "    plt.plot(epochs, train_loss)\n",
    "    plt.plot(epochs, valid_loss)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Training Loss','Validation Loss'])\n",
    "    \n",
    "    # Save data\n",
    "    if save:\n",
    "        torch.save(model.state_dict(), f'{train_name}.model')\n",
    "        plt.savefig(f'{train_name}_train.png')\n",
    "        with open(f'{train_name}_train.txt', \"w\") as text_file:\n",
    "            text_file.write(logger.get_log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47db0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, test_name, save=False):\n",
    "    \n",
    "    # Setup\n",
    "    logger = Log()\n",
    "    \n",
    "    # Testing\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    for inputs, labels in tqdm(test_dataloader, mininterval=1):\n",
    "        y_pred = model(inputs.to(dev))\n",
    "        acc += (torch.argmax(y_pred, 1) == labels.to(dev)).float().sum()\n",
    "    acc = 100 * float(acc) / len(test_dataloader.dataset)\n",
    "    logger.log(f\"Test accuracy {round(acc, 2)}\")\n",
    "    \n",
    "    # Saving\n",
    "    if save:\n",
    "        with open(f'{test_name}_test.txt', \"w\") as text_file:\n",
    "            text_file.write(logger.get_log())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e2632be",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c8a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image settings\n",
    "batch_size = 32\n",
    "gray = True\n",
    "\n",
    "# Model settings\n",
    "dropout_rate = 0.35\n",
    "\n",
    "# Training settings\n",
    "lr = 3\n",
    "momentum = 0.92\n",
    "epochs = 30\n",
    "\n",
    "# Scheduler settings\n",
    "patience = 2\n",
    "factor = 0.4\n",
    "\n",
    "# Name\n",
    "name = f\"{epochs}_SGD_{lr}_{momentum}_{dropout_rate}_{batch_size}_d_t{'g' if gray else ''}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a8ba449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(Data(train=0, gray=gray), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(Data(train=1, gray=gray), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(Data(train=2, gray=gray), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caceebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel(dropout_rate=dropout_rate, gray=gray).to(dev)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=10**(-lr), momentum=momentum)\n",
    "training(model, loss_fn, optimiser, epochs, name, save=True, patience=patience, factor=factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0cbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model, name, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
